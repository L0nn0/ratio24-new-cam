{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ir_datasets, get_output_directory\n",
    "from transformers import XLMRobertaForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load('workshop-on-open-web-search/query-processing-20231027-training')\n",
    "\n",
    "# Query processors persist their results in a file queries.jsonl in the output directory.\n",
    "output_file = Path(get_output_directory('.')) / 'queries.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = XLMRobertaForSequenceClassification.from_pretrained('OnnoLander/XLMRoberta-comparative-questions')\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query_text):\n",
    "    logits = model(**tokenizer(query_text, return_tensors=\"pt\")).logits\n",
    "    return {'is_comparative': int(logits.argmax()) == 1, 'is_comparative_logits': [float(i) for i in logits[0]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict some example: \"what is better, playstation or xbox?\"\n",
      "{'is_comparative': True, 'is_comparative_logits': [-5.1698899269104, 5.360167980194092]}\n"
     ]
    }
   ],
   "source": [
    "print('Predict some example: \"what is better, playstation or xbox?\"')\n",
    "print(predict('What is better, playstation or xbox?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict some example: \"playstation vs xbox\"\n",
      "{'is_comparative': True, 'is_comparative_logits': [-5.046789169311523, 5.182837963104248]}\n"
     ]
    }
   ],
   "source": [
    "print('Predict some example: \"playstation vs xbox\"')\n",
    "print(predict('playstation vs xbox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict some example: \"hubble telescope achievements\"\n",
      "{'is_comparative': False, 'is_comparative_logits': [4.803865909576416, -4.987368583679199]}\n"
     ]
    }
   ],
   "source": [
    "print('Predict some example: \"hubble telescope achievements\"')\n",
    "print(predict('hubble telescope achievements'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict some example: \"barack obama family tree\"\n",
      "{'is_comparative': False, 'is_comparative_logits': [4.693194389343262, -5.171028137207031]}\n"
     ]
    }
   ],
   "source": [
    "print('Predict some example: \"barack obama family tree\"')\n",
    "print(predict('barack obama family tree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  5.25it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_queries = []\n",
    "\n",
    "for query in tqdm(dataset.queries_iter()):\n",
    "    prediction = predict(query.text)\n",
    "    processed_queries += [{'query_id': query.query_id, 'is_comparative': prediction['is_comparative'], 'is_comparative_logits': prediction['is_comparative_logits']}]\n",
    "\n",
    "pd.DataFrame(processed_queries).to_json(output_file, lines=True, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
