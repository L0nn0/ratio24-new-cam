{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bondarenko/laptop/Jena/research/ACQuA/ratio-24/ratio24-new-cam\n",
      "/home/bondarenko\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path \n",
    "import os\n",
    "\n",
    "#set current working directory to the root\n",
    "if not os.getcwd().endswith('ratio24-new-cam'):\n",
    "    os.chdir('../')\n",
    "print(os.getcwd())\n",
    "print(Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>,object_0,object_1,answer,labels,xlm_5epochs</th>\n",
       "      <th>xlm_6epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0,Google,Apple,Life keeps on getting easier an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1,Bash,Python,\"Use of continuous integration t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2,JavaScript,PHP,\"Solid experience in HTML,[FI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3,halloween,thanksgiving,\"As if it could get a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4,basketball,baseball,\"It's true! Archery is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       ,object_0,object_1,answer,labels,xlm_5epochs  xlm_6epochs\n",
       "0           0  0,Google,Apple,Life keeps on getting easier an...            0\n",
       "1           1  1,Bash,Python,\"Use of continuous integration t...            0\n",
       "2           2  2,JavaScript,PHP,\"Solid experience in HTML,[FI...            0\n",
       "3           3  3,halloween,thanksgiving,\"As if it could get a...            0\n",
       "4           4  4,basketball,baseball,\"It's true! Archery is s...            0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_PATH = Path(\"results\")\n",
    "\n",
    "df_res = pd.read_csv(os.path.join(\n",
    "    INPUT_PATH, 'xlm_predictions_eng.csv'), sep=',')\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5759 1440 7199\n",
      "0:  0.73, 2:  0.19, 3:  0.08\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = Path(\"data\")\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(INPUT_PATH, \"comparg_train.tsv\"), sep='\\t', encoding='utf-8')  \n",
    "df_test = pd.read_csv(os.path.join(INPUT_PATH, \"comparg_test.tsv\"), sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(len(df_train), len(df_test), len(df_train)+len(df_test))\n",
    "labels = df_test.labels.tolist()\n",
    "print(f\"0: {labels.count(0)/len(labels): .2f}, 2: {labels.count(2)/len(labels): .2f}, 3: {labels.count(3)/len(labels): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n",
      "NONE:  0.70, BETTER:  0.21, WORSE:  0.08\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = Path(\"data\")\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(INPUT_PATH, \"ru_sentences_with_objs.tsv\"), sep='\\t', encoding='utf-8')\n",
    "print(len(df_test))\n",
    "labels = df_test.tag.tolist()\n",
    "print(f\"NONE: {labels.count('NONE')/len(labels): .2f}, BETTER: {labels.count('BETTER')/len(labels): .2f}, WORSE: {labels.count('WORSE')/len(labels): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 1, max: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER       0.86      0.89      0.87       273\n",
      "        NONE       0.95      0.95      0.95      1048\n",
      "       WORSE       0.71      0.69      0.70       119\n",
      "\n",
      "    accuracy                           0.91      1440\n",
      "   macro avg       0.84      0.84      0.84      1440\n",
      "weighted avg       0.91      0.91      0.91      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = Path(\"data\")\n",
    "df_res = pd.read_csv(os.path.join(INPUT_PATH, '5_epochs_comparg_test.tsv'), sep='\\t')\n",
    "# df_train = pd.read_csv(os.path.join(INPUT_PATH, 'comparg_train.tsv'), sep='\\t')\n",
    "df_res[\"pred_labels\"].replace({0: \"NONE\", 2: \"BETTER\", 3: \"WORSE\"}, inplace=True)\n",
    "df_res[\"labels\"].replace({0: \"NONE\", 2: \"BETTER\", 3: \"WORSE\"}, inplace=True)\n",
    "df_res[\"answer_words\"] = df_res[\"answer\"].apply(lambda x: len(x.split()))\n",
    "print(f\"min: {df_res.answer_words.min()}, max: {df_res.answer_words.max()}\")\n",
    "print(classification_report(y_true=df_res.labels, y_pred=df_res.pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER       0.96      0.90      0.93        50\n",
      "        NONE       0.98      1.00      0.99       257\n",
      "       WORSE       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           0.97       314\n",
      "   macro avg       0.87      0.82      0.84       314\n",
      "weighted avg       0.97      0.97      0.97       314\n",
      "\n",
      "0.22\n"
     ]
    }
   ],
   "source": [
    "y_true = df_res[(df_res.answer_words >=1) & (df_res.answer_words <= 10)].labels\n",
    "y_pred = df_res[(df_res.answer_words >=1) & (df_res.answer_words <= 10)].pred_labels\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(round(len(y_true)/len(df_res), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER       0.86      0.89      0.88       199\n",
      "        NONE       0.95      0.94      0.94       612\n",
      "       WORSE       0.74      0.73      0.73       100\n",
      "\n",
      "    accuracy                           0.91       911\n",
      "   macro avg       0.85      0.85      0.85       911\n",
      "weighted avg       0.91      0.91      0.91       911\n",
      "\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "y_true = df_res[(df_res.answer_words > 10) & (df_res.answer_words <= 30)].labels\n",
    "y_pred = df_res[(df_res.answer_words > 10) & (df_res.answer_words <= 30)].pred_labels\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(round(len(y_true)/len(df_res), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BETTER       0.65      0.83      0.73        24\n",
      "        NONE       0.94      0.91      0.92       179\n",
      "       WORSE       0.45      0.42      0.43        12\n",
      "\n",
      "    accuracy                           0.87       215\n",
      "   macro avg       0.68      0.72      0.69       215\n",
      "weighted avg       0.88      0.87      0.87       215\n",
      "\n",
      "0.15\n"
     ]
    }
   ],
   "source": [
    "y_true = df_res[(df_res.answer_words > 30)].labels\n",
    "y_pred = df_res[(df_res.answer_words > 30)].pred_labels\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(round(len(y_true)/len(df_res), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
